{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 153 images belonging to 7 classes.\n",
      "Found 42 images belonging to 7 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kanis\\AppData\\Local\\Temp\\ipykernel_7412\\2900839075.py:64: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = Classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5/5 [==============================] - 8s 2s/step - loss: 2.6074 - accuracy: 0.1438 - val_loss: 1.9950 - val_accuracy: 0.1429\n",
      "Epoch 2/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.9539 - accuracy: 0.1438 - val_loss: 1.9356 - val_accuracy: 0.1667\n",
      "Epoch 3/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 1.9252 - accuracy: 0.2353 - val_loss: 1.8594 - val_accuracy: 0.2143\n",
      "Epoch 4/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.8202 - accuracy: 0.2222 - val_loss: 1.6682 - val_accuracy: 0.4524\n",
      "Epoch 5/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.6725 - accuracy: 0.3725 - val_loss: 1.4415 - val_accuracy: 0.5476\n",
      "Epoch 6/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.5030 - accuracy: 0.4444 - val_loss: 1.3534 - val_accuracy: 0.4524\n",
      "Epoch 7/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2727 - accuracy: 0.5294 - val_loss: 1.1842 - val_accuracy: 0.6429\n",
      "Epoch 8/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0822 - accuracy: 0.6275 - val_loss: 1.0402 - val_accuracy: 0.5238\n",
      "Epoch 9/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.2867 - accuracy: 0.4837 - val_loss: 1.1211 - val_accuracy: 0.4524\n",
      "Epoch 10/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 1.0768 - accuracy: 0.5948 - val_loss: 1.0861 - val_accuracy: 0.5714\n",
      "Epoch 11/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.9251 - accuracy: 0.6863 - val_loss: 1.2443 - val_accuracy: 0.5238\n",
      "Epoch 12/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.8313 - accuracy: 0.6863 - val_loss: 1.1363 - val_accuracy: 0.5000\n",
      "Epoch 13/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.7690 - accuracy: 0.7451 - val_loss: 1.2025 - val_accuracy: 0.5952\n",
      "Epoch 14/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.6976 - accuracy: 0.7778 - val_loss: 1.0992 - val_accuracy: 0.4762\n",
      "Epoch 15/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.6394 - accuracy: 0.7908 - val_loss: 1.0075 - val_accuracy: 0.6190\n",
      "Epoch 16/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.6205 - accuracy: 0.8039 - val_loss: 1.5425 - val_accuracy: 0.5476\n",
      "Epoch 17/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.6926 - accuracy: 0.7386 - val_loss: 1.0389 - val_accuracy: 0.6190\n",
      "Epoch 18/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.8041 - accuracy: 0.6471 - val_loss: 1.3392 - val_accuracy: 0.6667\n",
      "Epoch 19/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.5595 - accuracy: 0.8235 - val_loss: 0.9899 - val_accuracy: 0.6667\n",
      "Epoch 20/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.5458 - accuracy: 0.8301 - val_loss: 1.0269 - val_accuracy: 0.5952\n",
      "Epoch 21/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3941 - accuracy: 0.8627 - val_loss: 0.9446 - val_accuracy: 0.6429\n",
      "Epoch 22/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3191 - accuracy: 0.8954 - val_loss: 1.1665 - val_accuracy: 0.6667\n",
      "Epoch 23/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2799 - accuracy: 0.8954 - val_loss: 1.5688 - val_accuracy: 0.5476\n",
      "Epoch 24/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.3493 - accuracy: 0.8954 - val_loss: 0.9943 - val_accuracy: 0.6905\n",
      "Epoch 25/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2847 - accuracy: 0.8954 - val_loss: 0.8220 - val_accuracy: 0.7143\n",
      "Epoch 26/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2196 - accuracy: 0.9346 - val_loss: 0.6601 - val_accuracy: 0.8095\n",
      "Epoch 27/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.2350 - accuracy: 0.9412 - val_loss: 1.0599 - val_accuracy: 0.7143\n",
      "Epoch 28/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.1444 - accuracy: 0.9739 - val_loss: 1.0380 - val_accuracy: 0.6905\n",
      "Epoch 29/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.1206 - accuracy: 0.9804 - val_loss: 1.1823 - val_accuracy: 0.7143\n",
      "Epoch 30/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0939 - accuracy: 0.9739 - val_loss: 1.1051 - val_accuracy: 0.7143\n",
      "Epoch 31/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0619 - accuracy: 0.9869 - val_loss: 0.8903 - val_accuracy: 0.7857\n",
      "Epoch 32/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0602 - accuracy: 0.9869 - val_loss: 1.8062 - val_accuracy: 0.7381\n",
      "Epoch 33/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0756 - accuracy: 0.9804 - val_loss: 1.1231 - val_accuracy: 0.7619\n",
      "Epoch 34/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0766 - accuracy: 0.9739 - val_loss: 1.7422 - val_accuracy: 0.7143\n",
      "Epoch 35/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0475 - accuracy: 0.9935 - val_loss: 0.8544 - val_accuracy: 0.7857\n",
      "Epoch 36/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0503 - accuracy: 0.9869 - val_loss: 0.8803 - val_accuracy: 0.8333\n",
      "Epoch 37/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0548 - accuracy: 0.9935 - val_loss: 1.3800 - val_accuracy: 0.6667\n",
      "Epoch 38/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 0.6992 - val_accuracy: 0.8571\n",
      "Epoch 39/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0324 - accuracy: 0.9935 - val_loss: 1.3097 - val_accuracy: 0.7619\n",
      "Epoch 40/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0228 - accuracy: 0.9935 - val_loss: 1.5924 - val_accuracy: 0.7857\n",
      "Epoch 41/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.6273 - val_accuracy: 0.7143\n",
      "Epoch 42/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.0454 - val_accuracy: 0.8095\n",
      "Epoch 43/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 1.8135 - val_accuracy: 0.7143\n",
      "Epoch 44/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0275 - accuracy: 0.9935 - val_loss: 0.8948 - val_accuracy: 0.8095\n",
      "Epoch 45/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.7961 - val_accuracy: 0.8571\n",
      "Epoch 46/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.0197 - val_accuracy: 0.7857\n",
      "Epoch 47/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.2413 - val_accuracy: 0.7381\n",
      "Epoch 48/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.7973 - val_accuracy: 0.7857\n",
      "Epoch 49/50\n",
      "5/5 [==============================] - 7s 1s/step - loss: 0.0314 - accuracy: 0.9869 - val_loss: 2.0367 - val_accuracy: 0.6905\n",
      "Epoch 50/50\n",
      "5/5 [==============================] - 6s 1s/step - loss: 0.0287 - accuracy: 0.9935 - val_loss: 1.4260 - val_accuracy: 0.7857\n",
      "Accuracy: 78.57%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "train_path = './Train'\n",
    "valid_path = './Test'\n",
    "\n",
    "# useful for getting number of output classes\n",
    "folders = glob('./Train/*')\n",
    "\n",
    "Classifier=Sequential()\n",
    "\n",
    "Classifier.add(Conv2D(32,(3,3), input_shape=(224,224,3), activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "Classifier.add(Conv2D(32,(3,3),activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "Classifier.add(Conv2D(64,(3,3),activation='relu'))\n",
    "Classifier.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "Classifier.add(Flatten())\n",
    "\n",
    "Classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "Classifier.add(Dense(units = 7, activation = 'softmax'))\n",
    "\n",
    "Classifier.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Use the Image Data Generator to import the images from the dataset\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory(\n",
    "    './Train',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    './Test',\n",
    "    target_size = (224, 224),\n",
    "    batch_size = 32,\n",
    "    class_mode = 'categorical')\n",
    "\n",
    "# fit the model\n",
    "r = Classifier.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=50,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")\n",
    "\n",
    "# save the model\n",
    "Classifier.save('model_Classifier.h5')\n",
    "\n",
    "# evaluate the model on the test set\n",
    "scores = Classifier.evaluate(test_set, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted Class: 6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model('model_Classifier.h5')\n",
    "\n",
    "# Load the test image\n",
    "img = image.load_img('./Test/Twentynote/2.jpg', target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "# Preprocess the image and make predictions\n",
    "img_array = img_array/255.0\n",
    "prediction = model.predict(img_array)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "# Print the predicted class\n",
    "print('Predicted Class:', predicted_class)\n",
    "from gtts import gTTS\n",
    "import os\n",
    "\n",
    "\n",
    "# Example text to convert to speech\n",
    "\n",
    "text = \"\"\n",
    "if predicted_class ==0:\n",
    "    text = \"100 rs Note\"\n",
    "elif predicted_class==1:\n",
    "    text = \"200 rs note\"\n",
    "elif predicted_class==2:\n",
    "    text = \"2000 rs note\"\n",
    "elif predicted_class==3:\n",
    "    text =\"500 rs note\"\n",
    "elif predicted_class==4:\n",
    "    text=\"50 rs note\"\n",
    "elif predicted_class==5:\n",
    "    text=\"10 rs note\"\n",
    "elif predicted_class==6:\n",
    "    text =\"20 rs note\"\n",
    "\n",
    "\n",
    "# Initialize a TTS object with the language (en) and the text to be spoken\n",
    "tts = gTTS(text=text, lang='en')\n",
    "\n",
    "# Save the audio file\n",
    "tts.save(\"currency_note.mp3\")\n",
    "\n",
    "# Play the audio file\n",
    "\n",
    "from playsound import playsound\n",
    "\n",
    "# path to the audio file\n",
    "audio_file_path = 'currency_note.mp3'\n",
    "\n",
    "# play the audio file\n",
    "playsound(audio_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
